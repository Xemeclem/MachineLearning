{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05bbe903-435f-4501-b203-14f4f37c0e69",
   "metadata": {},
   "source": [
    "采用PUDNN预测房价问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5b8d57-560f-4644-8bdb-ab2ef6c1df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, glob, zipfile\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b3f1174-6488-4ed3-a717-666b45a29626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理过程\n",
    "train_data = pd.read_csv('Data/train.csv') # type: DtaFrame, size: 1460 x 81\n",
    "test_data = pd.read_csv('Data/test.csv') # type: DtaFrame, size: 1459 x 80\n",
    "all_data = pd.concat((train_data.iloc[:,1:-1], test_data.iloc[:,1:])) # type: DtaFrame, size: (1460 + 1459) x 79 (去掉了数据的序号)\n",
    "# 1.数值数据进行标准化，标准化后，每个特征的均值变为 0，所以可以直接⽤ 0来替换缺失值\n",
    "numeric_features = all_data.dtypes[all_data.dtypes != 'object'].index # type: Index\n",
    "all_data[numeric_features] = all_data[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "all_data[numeric_features] = all_data[numeric_features].fillna(0)\n",
    "# 2.文本数据采用 one-hot 编码\n",
    "all_data = pd.get_dummies(all_data, dummy_na=True, dtype=int) # type: size: 2919 x 330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e929746-f4f5-476f-b178-e80f3178662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_inputs = all_data[:n_train].values\n",
    "train_labels = train_data.SalePrice.values.reshape(-1, 1)\n",
    "test_inputs = all_data[n_train:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e061b6-7a5b-4be5-b5fb-762bacab9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对标签进行Z-score标准化\n",
    "l_mean = train_labels.mean()\n",
    "l_std = train_labels.std()\n",
    "train_labels = (train_labels - l_mean)/l_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b08438-5137-43ee-98bd-08d96e6642f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydata(Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = torch.tensor(inputs, dtype = torch.float)\n",
    "        self.labels = torch.tensor(labels, dtype = torch.float)\n",
    "          \n",
    "    def __getitem__(self, item):\n",
    "        return self.inputs[item,:], self.labels[item,:]\n",
    "                                             \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0966a30-6862-4feb-a090-3353c2c3f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=6.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# PUMLP网络\n",
    "num_data = n_train\n",
    "num_centers = 100\n",
    "estimator = KMeans(n_clusters=num_centers).fit(train_inputs)\n",
    "centers = torch.tensor(estimator.cluster_centers_, dtype = torch.float)\n",
    "if torch.cuda.is_available():\n",
    "    centers = centers.cuda()\n",
    "    \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(in_features, (in_features+out_features)//2)\n",
    "        self.linear2 = nn.Linear((in_features+out_features)//2, out_features)\n",
    "        self.active = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.active(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        return self.active(x + y)   \n",
    "        \n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, depth):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        self.depth = depth\n",
    "        self.linear1 = nn.Linear(in_features, (in_features+out_features)//2)\n",
    "        self.dnn = nn.ModuleList([ResBlock((in_features+out_features)//2, (in_features+out_features)//2) for _ in range(self.depth)])\n",
    "        self.linear2 = nn.Linear((in_features+out_features)//2, out_features)\n",
    "        self.active = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.active(self.linear1(inputs))\n",
    "        for i in range(self.depth):\n",
    "            outputs = self.dnn[i](outputs)\n",
    "        outputs = self.linear2(outputs)\n",
    "        return outputs\n",
    "\n",
    "class PUDNN(nn.Module):\n",
    "    def __init__(self, in_features, out_features, depth):\n",
    "        super(PUDNN, self).__init__()\n",
    "        self.dnn  = DNN(in_features, out_features, depth)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # 距离矩阵\n",
    "        for i in range(inputs.shape[0]):\n",
    "            mid = torch.sum((inputs[i,:] - centers)**2, dim=1, keepdim=True)\n",
    "            if i < 1:\n",
    "                DM = mid.T\n",
    "            else:\n",
    "                DM = torch.cat((DM, mid.T), dim=0)\n",
    "        DM = self.softmax(DM)\n",
    "        for i in range(num_centers):\n",
    "            mid = self.dnn(inputs) * (DM[:,i].reshape(-1,1))\n",
    "            if i < 1:\n",
    "                outputs = mid\n",
    "            else:\n",
    "                outputs = outputs + mid\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f360fae0-bd39-4b6a-bf57-3451812a0a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集、设置网络训练的参数\n",
    "train_data = Mydata(train_inputs, train_labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "net = PUDNN(330, 1, 32)\n",
    "loss_fn = torch.nn.SmoothL1Loss()\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    loss_fn = loss_fn.cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b89f26-1f3b-46dc-a186-16d32ee271ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [04:49<11:15, 96.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     14\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())   \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型，并保存每一轮的总损失\n",
    "train_loss = []\n",
    "for i in tqdm(range(epoch)):\n",
    "    for data in train_dataloader:\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():            \n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())   \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d318f5-acc8-467e-bdfa-cf31225a81dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss[:])\n",
    "plt.title(\"train_loss\")\n",
    "train_loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f66127-c291-45a8-b1cd-5f97afc8e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(test_inputs[:1000], dtype=torch.float)\n",
    "preds1 = net(inputs.cuda()).detach().cpu().numpy()\n",
    "inputs = torch.tensor(test_inputs[1000:], dtype=torch.float)\n",
    "preds2 = net(inputs.cuda()).detach().cpu().numpy()\n",
    "preds = np.concatenate((preds1, preds2), axis=0)\n",
    "\n",
    "preds = preds * l_std + l_mean\n",
    "test_data['SalePrice'] = pd.Series(preds.reshape(1,-1)[0])\n",
    "submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
