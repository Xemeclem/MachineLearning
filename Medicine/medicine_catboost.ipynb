{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91cadba5-c871-4d8f-ac88-076e7bff0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tqdm, sys, os, gc, re, argparse, warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28efab9-f8c3-4b66-bd5f-dc0f769f3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('medicine_data/dataset-new/traindata-new.xlsx')\n",
    "test = pd.read_excel('medicine_data/dataset-new/testdata-new.xlsx')\n",
    "\n",
    "# test数据不包含 DC50 (nM) 和 Dmax (%)\n",
    "train = train.drop(['DC50 (nM)', 'Dmax (%)'], axis=1)\n",
    "\n",
    "# 去掉明显与结论无关的特征\n",
    "cols = ['Article DOI']\n",
    "train = train.drop(cols, axis=1)\n",
    "test = test.drop(cols, axis=1)\n",
    "\n",
    "# 定义了一个空列表drop_cols，用于存储在测试数据集中非空值小于10个的列名。\n",
    "drop_cols = []\n",
    "for f in test.columns:\n",
    "    if test[f].notnull().sum() < 10:\n",
    "        drop_cols.append(f)\n",
    "        \n",
    "# 使用drop方法从训练集和测试集中删除了这些列，以避免在后续的分析或建模中使用这些包含大量缺失值的列\n",
    "train = train.drop(drop_cols, axis=1)\n",
    "test = test.drop(drop_cols, axis=1)\n",
    "\n",
    "# 使用pd.concat将清洗后的训练集和测试集合并成一个名为data的DataFrame，便于进行统一的特征工程处理\n",
    "data = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "cols = data.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ecf502-1610-41f4-a608-1e4887f63fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将SMILES转换为分子对象列表,并转换为SMILES字符串列表\n",
    "data['smiles_list'] = data['Smiles'].apply(lambda x:[Chem.MolToSmiles(mol, isomericSmiles=True) for mol in [Chem.MolFromSmiles(x)]])\n",
    "data['smiles_list'] = data['smiles_list'].map(lambda x: ' '.join(x))  \n",
    "\n",
    "# 使用TfidfVectorizer计算TF-IDF\n",
    "tfidf = TfidfVectorizer(max_df = 0.9, min_df = 1, sublinear_tf = True)\n",
    "res = tfidf.fit_transform(data['smiles_list'])\n",
    "\n",
    "# 将结果转为dataframe格式\n",
    "tfidf_df = pd.DataFrame(res.toarray())\n",
    "tfidf_df.columns = [f'smiles_tfidf_{i}' for i in range(tfidf_df.shape[1])]\n",
    "\n",
    "# 按列合并到data数据\n",
    "data = pd.concat([data, tfidf_df], axis=1)\n",
    "\n",
    "# 自然数编码\n",
    "def label_encode(series):\n",
    "    unique = list(series.unique())\n",
    "    return series.map(dict(zip(\n",
    "        unique, range(series.nunique())\n",
    "    )))\n",
    "\n",
    "for col in cols:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col]  = label_encode(data[col])\n",
    "        \n",
    "train = data[data.Label.notnull()].reset_index(drop=True)\n",
    "test = data[data.Label.isnull()].reset_index(drop=True)\n",
    "\n",
    "# 特征筛选\n",
    "features = [f for f in train.columns if f not in ['uuid','Label','smiles_list']]\n",
    "\n",
    "# 构建训练集和测试集\n",
    "x_train = train[features]\n",
    "x_test = test[features]\n",
    "\n",
    "# 训练集标签\n",
    "y_train = train['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ff70ed-2cd1-45a1-8745-6775aff00202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************ 1 2022************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7630471\tbest: 0.7630471 (0)\ttotal: 92.9ms\tremaining: 30m 58s\n",
      "100:\ttest: 0.8956229\tbest: 0.9023569 (16)\ttotal: 517ms\tremaining: 1m 41s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9023569024\n",
      "bestIteration = 16\n",
      "\n",
      "Shrink model to first 17 iterations.\n",
      "[0.8686868686868686]\n",
      "************************************ 2 2022************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7300725\tbest: 0.7300725 (0)\ttotal: 5.01ms\tremaining: 1m 40s\n",
      "100:\ttest: 0.9456522\tbest: 0.9456522 (100)\ttotal: 394ms\tremaining: 1m 17s\n",
      "200:\ttest: 0.9619565\tbest: 0.9628623 (160)\ttotal: 795ms\tremaining: 1m 18s\n",
      "300:\ttest: 0.9673913\tbest: 0.9682971 (269)\ttotal: 1.21s\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9682971014\n",
      "bestIteration = 269\n",
      "\n",
      "Shrink model to first 270 iterations.\n",
      "[0.8686868686868686, 0.9361702127659574]\n",
      "************************************ 3 2022************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7331175\tbest: 0.7331175 (0)\ttotal: 4.82ms\tremaining: 1m 36s\n",
      "100:\ttest: 0.9296947\tbest: 0.9333950 (77)\ttotal: 426ms\tremaining: 1m 23s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9333950046\n",
      "bestIteration = 77\n",
      "\n",
      "Shrink model to first 78 iterations.\n",
      "[0.8686868686868686, 0.9361702127659574, 0.8888888888888888]\n",
      "************************************ 4 2022************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7751020\tbest: 0.7751020 (0)\ttotal: 5.8ms\tremaining: 1m 55s\n",
      "100:\ttest: 0.8938776\tbest: 0.8946939 (87)\ttotal: 417ms\tremaining: 1m 22s\n",
      "200:\ttest: 0.8979592\tbest: 0.8979592 (144)\ttotal: 847ms\tremaining: 1m 23s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.8979591837\n",
      "bestIteration = 144\n",
      "\n",
      "Shrink model to first 145 iterations.\n",
      "[0.8686868686868686, 0.9361702127659574, 0.8888888888888888, 0.8571428571428571]\n",
      "************************************ 5 2022************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7835145\tbest: 0.7835145 (0)\ttotal: 5.33ms\tremaining: 1m 46s\n",
      "100:\ttest: 0.9538043\tbest: 0.9592391 (75)\ttotal: 405ms\tremaining: 1m 19s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.9592391304\n",
      "bestIteration = 75\n",
      "\n",
      "Shrink model to first 76 iterations.\n",
      "[0.8686868686868686, 0.9361702127659574, 0.8888888888888888, 0.8571428571428571, 0.9278350515463919]\n",
      "cat_score_list: [0.8686868686868686, 0.9361702127659574, 0.8888888888888888, 0.8571428571428571, 0.9278350515463919]\n",
      "cat_score_mean: 0.8957447758061928\n",
      "cat_score_std: 0.03141096432159168\n"
     ]
    }
   ],
   "source": [
    "def cv_model(clf, train_x, train_y, test_x, clf_name, seed=2022):\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "    train = np.zeros(train_x.shape[0])\n",
    "    test = np.zeros(test_x.shape[0])\n",
    "\n",
    "    cv_scores = []\n",
    "    # 100， 1 2 3 4 5\n",
    "    # 1 2 3 4    5\n",
    "    # 1 2 3 5。  4\n",
    "    # 1\n",
    "    for i, (train_index, valid_index) in enumerate(kf.split(train_x, train_y)):\n",
    "        print('************************************ {} {}************************************'.format(str(i+1), str(seed)))\n",
    "        trn_x, trn_y, val_x, val_y = train_x.iloc[train_index], train_y[train_index], train_x.iloc[valid_index], train_y[valid_index]\n",
    "               \n",
    "        params = {'learning_rate': 0.1, 'depth': 6, 'l2_leaf_reg': 10, 'bootstrap_type':'Bernoulli','random_seed':seed,\n",
    "                  'od_type': 'Iter', 'od_wait': 100, 'allow_writing_files': False, 'task_type':'CPU'}\n",
    "\n",
    "        model = clf(iterations=20000, **params, eval_metric='AUC')\n",
    "        model.fit(trn_x, trn_y, eval_set=(val_x, val_y),\n",
    "                  metric_period=100,\n",
    "                  cat_features=[], \n",
    "                  use_best_model=True, \n",
    "                  verbose=1)\n",
    "\n",
    "        val_pred  = model.predict_proba(val_x)[:,1]\n",
    "        test_pred = model.predict_proba(test_x)[:,1]\n",
    "            \n",
    "        train[valid_index] = val_pred\n",
    "        test += test_pred / kf.n_splits\n",
    "        cv_scores.append(f1_score(val_y, np.where(val_pred>0.5, 1, 0)))\n",
    "        \n",
    "        print(cv_scores)\n",
    "       \n",
    "    print(\"%s_score_list:\" % clf_name, cv_scores)\n",
    "    print(\"%s_score_mean:\" % clf_name, np.mean(cv_scores))\n",
    "    print(\"%s_score_std:\" % clf_name, np.std(cv_scores))\n",
    "    return train, test\n",
    "    \n",
    "cat_train, cat_test = cv_model(CatBoostClassifier, x_train, y_train, x_test, \"cat\")\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'uuid': test['uuid'],\n",
    "        'Label': np.where(cat_test>0.5, 1, 0)\n",
    "    }\n",
    ").to_csv('submit.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
